//GLFW Defines and includes
#define GLFW_INCLUDE_VULKAN
#include <GLFW/glfw3.h>

//C++ includes
#include <iostream>
#include <stdexcept>
#include <functional>
#include <cstdlib>
#include <vector>
#include <map>
#include <set>
#include <algorithm>
#include <fstream>
#include <array>
#include <unordered_map>

//Exposes functions to do precise timekeeping.
#include <chrono>

//GLM Defines and includes
//GLM_FORCE_RADIANS definition is necessary to make sure that functions like glm::rotate use radians as arguments
//to avoid any possible confusion.
#define GLM_FORCE_RADIANS

//The persepective proj matrix generated by GLM will use the OpenGL depth range of -1.0 to 1.0 by default.
//We need to configure it to use the Vulkan range of 0.0 to 1.0 using the GLM_FROCE_DEPTH_ZERO_TO_ONE defintion.
#define GLM_FORCE_DEPTH_ZERO_TO_ONE
#include <glm/glm.hpp>

//The hash functions are defined in the gtx folder, which means that it is techniacally still an experimental
//extension to GLM. Therefore you need to define GLM_ENABLE_EXPPERTIMENTAL to use it. It means that the API could
//change with a new version of GLM in the future, but in practive the API is very stable
#define GLM_ENABLE_EXPERIMENTAL
#include <glm/gtx/hash.hpp>

//Exposes functions that can be used to generate model transformations like glm::rotate, 
//view transformations like glm::lookat
//proj transformation like glm::perspective.
#include <glm/gtc/matrix_transform.hpp>

#define STB_IMAGE_IMPLEMENTATION
#include <stb/stb_image.h>

//Define to include the function bodies and avoid linker issues
#define TINYOBJLOADER_IMPLEMENTATION
#include <syoyo/tiny_obj_loader.h>

//Custom includes:
#include "Window.h"
#include "../Vulkan/VulkanInstance.h"
#include "../Vulkan/Surface.h"
#include "../Vulkan/PhysicalDevice.h"
#include "../Vulkan/LogicalDevice.h"
#include "../Vulkan/SwapChain.h"
#include "../Vulkan/RenderPass.h"
#include "../Vulkan/DescriptorSetLayout.h"
#include "../Vulkan/PipelineLayout.h"
#include "../Vulkan/GraphicsPipeline.h"
#include "../Vulkan/Vertex.h"
#include "../Vulkan/CommandPool.h"
#include "../Vulkan/Buffer2D.h"

#include "../Help/HelperMethods.h"

//Create different queue family specifically for transfer operatinos. It will require you the following changes:
//1) Modify QueueFamilyIndices and FindQueueFamilies to explicitly look for a queue family with the VK_QUEUE_TRANSFER bit,
//but not the VK_QUEUE_GRAPHICS_BIT.
//2) Modify CreateLogicalDevice to request a handle to the transfer queue
//3) Create a second command pool for command buffers that are submitted on the transfer queue family
//4) Change the sharingMode of resources to be VK_SHARING_MODE_CONCURRENT and specify both the graphics and transfer queue families
//5) Submit any transfer command like vkCmdCopyBuffer to the transfer queue instead of the graphics queue

//Shader stages: the shader modules that define the functionality of the programmable stages of the graphics pipeline
//Fixed-function state: all of the structures that define the fixed-functoins stages of the pipeline, like input assembly, rasterizer, viewport and color blending
//Pipeline layout: the uniform and push values referenced by the shader that can be updated at draw time
//Render pass: the attachments referenced by the pipeline stages and their usage

/*
struct UniformBufferObject
{
	glm::mat4 model;
	glm::mat4 view;
	glm::mat4 proj;
};

Vertex Shader:
layout(binding = 0) unifomr UniformBufferObject
{
	mat4 model;
	mat4 view;
	mat4 proj;
} ubo;

void main()
{
	gl_Position = ubo.proj * ubo.view * ubo.model * vec4(inPosition, 0.0f, 1.0f);
	fragColor = inColor;
}
*/

//How to add a texture:
//Create an image object backed by device memory
//Fill it with pixels from an image file
//Create an image sampler
//Add a combined image sampler descriptor to sample colors from the texture

//One of the most common ways to transition the layout of an image is a pipeline barrier.
//Pipeline barriers are primarily used for synchrnizing access to resources, like making sure an image was
//written to before it is read, but they can also be used to transition layouts
//Barriers can additionally be used to transfer queue family ownership when using VK_SHARING_MODE_EXCLUSIVE

//To solve that images aren't drawn over each other:
//Sort all of the draw calls by depth from back to front(used for drawing transparent objects)
//Depth testing

//Possible extentions to the program:
//Push constants
//Instanced rendering
//Dynamic uniforms
//Separate images and sampler descriptors
//Pipeline cache
//Multi-threaded command buffer generation
//Multiple subpasses
//Compute shaders


namespace std
{
	template<> struct hash<Vertex>
	{
		size_t operator()(Vertex const& vertex) const
		{
			return ((hash<glm::vec3>()(vertex.Position) ^ 
				(hash<glm::vec3>()(vertex.Color) << 1)) >> 1) ^ 
				(hash<glm::vec2>()(vertex.TexCoord) << 1);
		}
	};
}

class HelloTriangleApplication
{
public:
	HelloTriangleApplication()
	{
		m_UniqueWindow = std::make_unique<Window>(WIDTH, HEIGHT, "VulkanTestProject", false);
		m_UniqueInstance = std::make_unique<VulkanInstance>(true);
		m_UniqueSurface = std::make_unique<Surface>(m_UniqueInstance->GetInstance(), m_UniqueWindow->GetGLFWWindow());
	}

	void Run()
	{
		InitializeVulkan();
		MainLoop();
		Cleanup();
	}

private:
	void InitializeVulkan()
	{
		PickPhysicalDevice();
		m_UniqueCpu = std::make_unique<LogicalDevice>(m_UniqueInstance.get(), m_UniqueGpu.get(), m_DeviceExtensions, m_ValidationLayers);
		m_UniqueSwapChain = std::make_unique<SwapChain>(m_UniqueGpu.get(), m_UniqueWindow.get(), m_UniqueSurface.get(), m_UniqueCpu.get());
		m_UniqueSwapChain->CreateImageViews();
		m_UniqueRenderPass = std::make_unique<RenderPass>(m_UniqueCpu.get(), m_UniqueSwapChain.get(), m_UniqueGpu.get());
		m_UniqueDescriptorSetLayout = std::make_unique<DescriptorSetLayout>(m_UniqueCpu.get());
		m_UniquePipeline = std::make_unique<GraphicsPipeline>(m_UniqueCpu.get(), m_UniqueSwapChain.get(), m_UniqueRenderPass.get(), m_UniqueDescriptorSetLayout.get());
		m_UniqueCommandPool = std::make_unique<CommandPool>(m_UniqueCpu.get(), m_UniqueGpu.get());

		CreateColorResources();
		CreateDepthResources();
		m_UniqueSwapChain->CreateFrameBuffers(m_UniqueRenderPass->GetRenderPass(), m_UniqueRenderTarget->GetImageView(), m_UniqueDepthBuffer->GetImageView());
		CreateTextureImage();
		CreateTextureImageView();
		CreateTextureSampler();
		LoadModel();
		CreateVertexBuffer();
		CreateIndexBuffer();
		m_UniqueSwapChain->CreateUniformBuffer();
		CreateDescriptorPool();
		CreateDescriptorSets();
		CreateCommandBuffers();
		CreateSyncObjects();
	}

	void MainLoop()
	{
		while (!glfwWindowShouldClose(m_UniqueWindow->GetGLFWWindow()))
		{
			glfwPollEvents();
			DrawFrame();
		}

		vkDeviceWaitIdle(m_UniqueCpu->GetDevice());
	}

	void Cleanup()
	{
		//Clean vulkan
		CleanupSwapChain();

		vkDestroySampler(m_UniqueCpu->GetDevice(), m_TextureSampler, nullptr);

		vkDestroyDescriptorPool(m_UniqueCpu->GetDevice(), m_DescriptorPool, nullptr);

		vkDestroyBuffer(m_UniqueCpu->GetDevice(), m_IndexBuffer, nullptr);
		vkFreeMemory(m_UniqueCpu->GetDevice(), m_IndexBufferMemory, nullptr);

		vkDestroyBuffer(m_UniqueCpu->GetDevice(), m_VertexBuffer, nullptr);
		vkFreeMemory(m_UniqueCpu->GetDevice(), m_VertexBufferMemory, nullptr);

		for (size_t i = 0; i < MAX_FRAMES_IN_FLIGHT; ++i)
		{
			vkDestroySemaphore(m_UniqueCpu->GetDevice(), m_RenderFinishedSemaphores[i], nullptr);
			vkDestroySemaphore(m_UniqueCpu->GetDevice(), m_ImageAvailableSemaphores[i], nullptr);
			vkDestroyFence(m_UniqueCpu->GetDevice(), m_InFlightFences[i], nullptr);
		}

		glfwTerminate();
	}

	std::vector<VkPhysicalDevice> FindGpus()
	{
		uint32_t gpuCount = 0;
		vkEnumeratePhysicalDevices(m_UniqueInstance->GetInstance(), &gpuCount, nullptr);

		if (gpuCount == 0)
			throw std::runtime_error("failed to find GPUs with Vulkan support!");

		std::vector<VkPhysicalDevice> gpus(gpuCount);
		vkEnumeratePhysicalDevices(m_UniqueInstance->GetInstance(), &gpuCount, gpus.data());

		return gpus;
	}

	void PickPhysicalDevice()
	{
		std::vector<VkPhysicalDevice> gpus = FindGpus();

		if (gpus.empty())
			throw std::runtime_error("no gpus found!");

		VkPhysicalDevice pickedPhysicalDevice = VK_NULL_HANDLE;

		std::set<std::string> requiredExtensions(m_DeviceExtensions.begin(), m_DeviceExtensions.end());

		//Check all the possible gpus and disregard those who aren't suitable

		//For those who are suitable, sort from best to worst
		//Use an ordered map to automatically sort candidates by descending score
		std::multimap<int, PhysicalDevice, std::greater<int>> candidates;
		
		for (const VkPhysicalDevice& gpu : gpus)
		{
			PhysicalDevice physicalDevice(m_UniqueSurface.get(), gpu, requiredExtensions);

			std::cout << "Checking " << physicalDevice.GetDesc().Properties.deviceName << std::endl;

			if (physicalDevice.IsSuitable())
			{
				int score = physicalDevice.RateSuitability();
				
				candidates.insert(std::make_pair(score, physicalDevice));
				//break;
			}
		}

		//Check if the best candidate is suitable at all
		if (candidates.cbegin()->first > 0)
			m_UniqueGpu = std::make_unique<PhysicalDevice>(candidates.cbegin()->second);
		else
			throw std::runtime_error("failed to find a suitable GPU!");
		
		std::cout << "Using: " << m_UniqueGpu->GetDesc().Properties.deviceName << std::endl;
	}

	void CreateCommandBuffers()
	{
		m_CommandBuffers.resize(m_UniqueSwapChain->GetFrameBuffers().size());

		VkCommandBufferAllocateInfo allocInfo = {};
		allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
		allocInfo.commandPool = m_UniqueCommandPool->GetPool();

		//The level parameter specifies if the allocated command buffers are primary or secondary command buffers.
		//VK_COMMAND_BUFFER_LEVEL_PRIMARY: Can be submitted to a queue for exection, but cannot be called from other command buffers.
		//VK_COMMAND_BUFFER_LEVEL_SECONDARY: Cannot be submitted directly, but can be called from primary command buffers.
		allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY;
		allocInfo.commandBufferCount = (uint32_t)m_CommandBuffers.size();

		if (vkAllocateCommandBuffers(m_UniqueCpu->GetDevice(), &allocInfo, m_CommandBuffers.data()) != VK_SUCCESS)
			throw std::runtime_error("failed to allocate command buffers!");

		for (size_t i = 0; i < m_CommandBuffers.size(); ++i)
		{
			VkCommandBufferBeginInfo beginInfo = {};
			beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;

			//The flags parameter specifies how we're going to use the command buffer. the following values are available:
			//VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT: The command buffer will be rerecorded right after executing one.
			//VK_COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT: This is a secondary command buffer that will be entirely within a single render pass.
			//VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT: The command buffer can be resubmitted while it is also already pending exection.
			beginInfo.flags = VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT;

			//This is relevant for secondary command bufffers.
			//it specifies which state to inherit from the calling primary command buffers
			beginInfo.pInheritanceInfo = nullptr; //Optional

			//If the command buffer was already recorded once, then a call to vkBeginCommandBuffer will implicitly reset it..'
			//it's not possiblke to append command to a buffer at a later time.

			if (vkBeginCommandBuffer(m_CommandBuffers[i], &beginInfo) != VK_SUCCESS)
				throw std::runtime_error("failed to begin recording command buffer!");

			VkRenderPassBeginInfo renderPassInfo = {};
			renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO;
			renderPassInfo.renderPass = m_UniqueRenderPass->GetRenderPass();
			renderPassInfo.framebuffer = m_UniqueSwapChain->GetFrameBuffers()[i];

			//the render area defines where shader loads and stores will take place.
			//The pixels outside this region will have undefined values. It should match the size of the attachments for best performance.
			renderPassInfo.renderArea.offset = { 0,0 };
			renderPassInfo.renderArea.extent = m_UniqueSwapChain->GetExtent();

			std::array<VkClearValue, 2> clearValues = {};
			clearValues[0].color = { 0.0f, 0.0f, 0.0f, 1.0f };

			//the range of depths in the depth buffer is 0.0 to 1.0 in Vulkan, where 1.0 lies at the far view plane and
			// 0.0 at the near view plane. The initial value at each point in the depth buffer should be the furthest
			//possible depth, which is 1.0
			clearValues[1].depthStencil = { 1.0f, 0 };

			//These parameters define the clear value to use for VK_ATTACHMENT_LOAD_OP_CLEAR
			//which we used as load operation for the color attachment.
			//I've defined the clear color to simply be black 100% opacity
			renderPassInfo.clearValueCount = static_cast<uint32_t>(clearValues.size());
			renderPassInfo.pClearValues = clearValues.data();

			//VK_SUBPASS_COONTENTS_INLINE: The render pass commands will be embedded in the primary command buffer itself 
			//and no secondary dommand will be executed

			//VK_SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS: The render pass commands iwll be executed from secondary command buffers.
			vkCmdBeginRenderPass(m_CommandBuffers[i], &renderPassInfo, VK_SUBPASS_CONTENTS_INLINE);

			vkCmdBindPipeline(m_CommandBuffers[i], VK_PIPELINE_BIND_POINT_GRAPHICS, m_UniquePipeline->GetPipeline());

			VkBuffer vertexBuffers[] = { m_VertexBuffer };
			VkDeviceSize offsets[] = { 0 };

			//The first 2 parameters, besides the command buffer, specify the offset and number of bindings
			//we're going to specify vertex buffers for. The last 2 paramets specify the array of vertex buffers
			//to bind and the byte offsets to start reading vertex data from.
			vkCmdBindVertexBuffers(m_CommandBuffers[i], 0, 1, vertexBuffers, offsets);

			//An index buffer is bound with vkCmdBindIndexBuffer which has the index buffer, a byte offset into it,
			//and the type of the index data as parameters.
			//The possible types are VK_INDEX_TYPE_UINT16 and VK_INDEX_TYPE_UINT32
			vkCmdBindIndexBuffer(m_CommandBuffers[i], m_IndexBuffer, 0, VK_INDEX_TYPE_UINT32);
			//The actual vkCmdDraw function is a bit anti climactic, but it's so simple because of all the information we specified in advance.
			//It has the following parameters, aside from the command buffer.

			//Drawing without indices:
			//vertexCount: Even though we don't have a vertex buffer, we technically still have 3 vertices to draw.
			//instanceCount: Used for instanced rendering, use 1 if you're not doing that.
			//firstVertex: Used as an offset into the vertex buffer, defines the lowest value of gl_VertexIndex
			//firstInstance: used as an offset for instanced rendering, defines the lowest value of gl_InstanceIndex.
			//vkCmdDraw(m_CommandBuffers[i], static_cast<uint32_t>(m_Vertices.size()), 1, 0, 0);

			//Unlike vertex and index buffers, descriptor sets are not unique to graphics pipelines.
			//Therefore we need to specify if we want to bind descriptor sets to the graphics or compute pipeline.
			//The next parameter is the layout that the descriptors are based on.
			//The next 3 parameters specify the index of the first descriptor set, the number of sets to bind and
			//the array of sets to bind.
			//The last 2 parameetres specify an array of offsets that are used for dynamic descriptors.
			vkCmdBindDescriptorSets(m_CommandBuffers[i], VK_PIPELINE_BIND_POINT_GRAPHICS, m_UniquePipeline->GetLayout()->GetPipelineLayout(), 0, 1, &m_DescriptorSets[i], 0, nullptr);

			//A call to this funtion is very similar to vkCmdDraw. the first 2 parameters specify the number of indices
			//and the number of instances. We're not using instancing, so just specify 1 instance.
			//The number of indices represents the number of vertices that will bepassed to the vertex buffer.
			//The next parameter specifies an offset into the index buffer, using a value of 1 would cause the graphics card
			//to start reading at the second index. The second to last parameter speicifes an offset to add to the indices
			//in the index buffer. the final parameter specifies an offset for instancing, which we're not using.

			//Driver developers recommend that you also store mutliple buffers, like the vertex and index buffer,
			//into a single VkBuffer and use offsets in commands like vkCmdBindVertexBuffers. The advantage is that your data
			//is more cache friendly in that case, because it's closer together. It is even possible to reuse the same chunk
			//of memory for multiple resources if they are not used during the same render operations, provided that their data
			//is refreshed, of course. This is known as aliasing and some Vulkan functions have explicit flags to specify that you 
			//want to do this.
			vkCmdDrawIndexed(m_CommandBuffers[i], static_cast<uint32_t>(m_Indices.size()), 1, 0, 0, 0);

			vkCmdEndRenderPass(m_CommandBuffers[i]);

			if (vkEndCommandBuffer(m_CommandBuffers[i]) != VK_SUCCESS)
				throw std::runtime_error("failed to record command buffers!");
		}

	}

	void DrawFrame()
	{
		//Wait for the frame to be finished
		//To learn more about synchrnoization through examples,
		//have a look at this extensive overview by Kronos
		//https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples#swapchain-image-acquire-and-present

		//The vkWaitForFences function takes an array of fences and wait for either any or all of them to be signaled before returning.
		//The VK_TRUE we pass here indicates that we want to wait for all fences, but in the case of a single one it obviouslt doesn't matter.
		//just like vkAcquireNExtImageKHR this function also takes a timeout. 
		vkWaitForFences(m_UniqueCpu->GetDevice(), 1, &m_InFlightFences[m_CurrentFrame], VK_TRUE, std::numeric_limits<uint64_t>::max());

		//The function calls that get called in this method will return before the operations are actually finished,
		//and the order of execution is also undefined. That's unfortunate, because each of the operations depends on the previous one finishing.
		//There are two ways of synchronizing swap chain events: fences and semaphores. They're both objects that can be used
		//for coordinating operations by having one operation signal and another operation wait for a fence or semaphore to go from the unsignaled to signaled state.
		//The difference is that the state of fences can be accessed from your program using calls like vkWaitForFences and semaphores cannot be.
		//Fences are mainly designed to synchronize your aplicatoin itself with rendering operation, whereas semaphores are used to synchronize operations
		//within or across command queues.
		//We want to synchronize the queue operations of draw commands and presenation, which makes semaphores the best fit.

		//the first thing we need to do is acquire an image from the swap chain.
		uint32_t imageIndex;

		//The first 2 parameters of vkAcquireNextImageKHR are the logical device and the swap chain from which we wish to acquire an image.
		//The third parameter specifies a timeout in nanoseconds for an image to become visible.
		//using the maximum value of a 64 bit unsigned integer disables the timeout.
		//The next 2 parameters specify synchronization objects that are to be signaled when the presenation engine is finished using the image.
		//That's the point in time where we can start drawing to it. It is possible to specify a semaphore, fence or both.
		//We're going to use our m_ImageAvailableSemaphore for that purporse here.
		//The last parameter specifies a variable to output the index of the swap chain image that has become available.
		//The index refers to the VkImage in our m_SwapChainImages array. We're going to use that index to pick the right command buffer.

		VkResult result = vkAcquireNextImageKHR(m_UniqueCpu->GetDevice(), m_UniqueSwapChain->GetSwapChain(), std::numeric_limits<uint64_t>::max(), m_ImageAvailableSemaphores[m_CurrentFrame], VK_NULL_HANDLE, &imageIndex);

		//if the swap chain turns out to be out of date when attempting to qcquire an image,
		//then it is no longer possible to present it.
		//Therefore we should immediately recreate the swap chain and try again in the next DrawFrame call.
		//However, if we abort drawing at this point, then the fence will never have been submitted with vkQueueSubmit
		//and it'll be in an unexpected state when we try to wait for it later on.
		//We could recreate the fences as part of the swap chain recreation but it's easier to move the vkResetFences call
		if (result == VK_ERROR_OUT_OF_DATE_KHR)
		{
			RecreateSwapChain();
			return;
		}
		else if (result != VK_SUCCESS && result != VK_SUBOPTIMAL_KHR)
			throw std::runtime_error("failed to acquire swap chain image!");

		m_UniqueSwapChain->UpdateUniformBuffer(imageIndex);

		VkSubmitInfo submitInfo = {};
		submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;

		//the first 3 parameters specify which semaphores to wait on before execution begins and in which stage(s) of the pipeline to wait.
		//We want to wait with writing colors to the image untill it's available, so we're specifying the stage of the graphics pipelines
		//that writes to the color attachment. That means that theoretically the implementation can already start executing our vertex shader and such
		//while the image is not yet available, each entry in the waitStages array corresponds to the semaphore with the same index in pWaitSemaphores.
		VkSemaphore waitSemaphores[] = { m_ImageAvailableSemaphores[m_CurrentFrame] };
		VkPipelineStageFlags waitStages[]{ VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT };
		submitInfo.waitSemaphoreCount = 1;
		submitInfo.pWaitSemaphores = waitSemaphores;
		submitInfo.pWaitDstStageMask = waitStages;

		//The next 2 parameters specify which command buffers to actually submit for execution. As mentioned earlier
		//We should submit the command buffer that binds the swap chain image we just acquired as color attachment.
		submitInfo.commandBufferCount = 1;
		submitInfo.pCommandBuffers = &m_CommandBuffers[imageIndex];

		//The signalSemaphoreCount and pSigneSemaphores parameters specify which semaphores to signal once the command buffer(s) have finished execution.
		//In our case we're using the m_RenderFinishedSemaphore for that purpose.
		VkSemaphore signalSemaphores[] = { m_RenderFinishedSemaphores[m_CurrentFrame] };
		submitInfo.signalSemaphoreCount = 1;
		submitInfo.pSignalSemaphores = signalSemaphores;

		//Unlike the semaphores, we manually need to restore the fence
		//to the unsignaled state by resetting it with the vkResetFence call.
		vkResetFences(m_UniqueCpu->GetDevice(), 1, &m_InFlightFences[m_CurrentFrame]);

		//We can now submit the command buffer to the graphics queue using vkQueueSubmit.
		//the function takes an array of VkSubmitInfo structues as argument for efficiency when the workload is much larger.
		//The last parameter references an optional fence that will be signaled when the command buffers finish execution.
		///Deprecated: We're using semaphores for synchronization, so we'll just pass a VK_NULL_HANDLE
		if (vkQueueSubmit(m_UniqueCpu->GetGraphicsQueue(), 1, &submitInfo, m_InFlightFences[m_CurrentFrame]) != VK_SUCCESS)
			throw std::runtime_error("failed to submit draw command buffer!");

		VkPresentInfoKHR presentInfo = {};
		presentInfo.sType = VK_STRUCTURE_TYPE_PRESENT_INFO_KHR;

		//The first 2 parameters specify which semaphores to wait on before presentation can happen, just like VkSubmitInfo.
		presentInfo.waitSemaphoreCount = 1;
		presentInfo.pWaitSemaphores = signalSemaphores;

		VkSwapchainKHR swapChains[] = { m_UniqueSwapChain->GetSwapChain() };

		//The next 3 parameters specify the swap chains to present images to and the index of the image for each swap chain.
		//This will almost always be a single one.
		presentInfo.swapchainCount = 1;
		presentInfo.pSwapchains = swapChains;
		presentInfo.pImageIndices = &imageIndex;

		//There is one last optional parameter called pResults.
		//It allows you to specify an array of VkResult values to check for every individual swap chain if presentation was successful.
		//It's not necessary if you're only using a single swap chain, because you can simply use the return value of the present function.
		presentInfo.pResults = nullptr; //Optional

		//The vkQueuePresentKHR function submits the request to present an image to the swap chain.
		//We'll add error handling for both vkAcquireNextImageKHR and vkQeuuePresentKGR in the next chapter, because their failure
		//does not necessarily mean the program should terminate, unlike the functions we've seen so far
		//The vkQueuePresentKHR also return the same values as before. In this case we will also recreate the swap chain
		//if is is suboptimal, because we want the best possible result.
		result = vkQueuePresentKHR(m_UniqueCpu->GetPresentQueue(), &presentInfo);

		if (result == VK_ERROR_OUT_OF_DATE_KHR || result == VK_SUBOPTIMAL_KHR || m_FrameBufferResized)
		{
			m_FrameBufferResized = false;
			RecreateSwapChain();
		}
		else if (result != VK_SUCCESS)
			throw std::runtime_error("failed to present swap chain image!");

		//If you run your application with validation layers enabled and you monitor the memory usage of your application,
		//you may notice that is is slowly growing. The reason for this is that the applicatoin is rapidly submitting work in the DrawFrame
		//function, but doesn't actually check if any of it finishes. If the CPU is submitting work faster than the GPU can keep up with then
		//the queue will slowly fill up with work. Worse, even, is that we are reusing the m_ImageAvailableSemaphores
		//and m_RenderFinishedSemaphore for multile frames at the same time.

		//The easy way to solve this is to wait for work to finish right after submitting it, for example by using vkQueueWaitIdle.
		vkQueueWaitIdle(m_UniqueCpu->GetPresentQueue());

		//However, we are likely not optimally using the GPU in this way, because the whole graphics pipeline is only
		//used for one frame at a time right now. The stages that the current frame has already progressed through are idle and
		//could already be used for a next frame.
		m_CurrentFrame = (m_CurrentFrame + 1) % MAX_FRAMES_IN_FLIGHT;
	}

	//Create semaphores and fences
	void CreateSyncObjects()
	{
		m_ImageAvailableSemaphores.resize(MAX_FRAMES_IN_FLIGHT);
		m_RenderFinishedSemaphores.resize(MAX_FRAMES_IN_FLIGHT);
		m_InFlightFences.resize(MAX_FRAMES_IN_FLIGHT);

		VkSemaphoreCreateInfo semaphoreInfo = {};
		semaphoreInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;

		VkFenceCreateInfo fenceInfo = {};
		fenceInfo.sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO;

		//Initialize a fence in the signaled state as if we already rendered a frame
		//this is to make sure the VkWaitForFences doesn't wait for ever for the first frame to be rendered.
		fenceInfo.flags = VK_FENCE_CREATE_SIGNALED_BIT;

		for (size_t i = 0; i < MAX_FRAMES_IN_FLIGHT; ++i)
		{
			if (vkCreateSemaphore(m_UniqueCpu->GetDevice(), &semaphoreInfo, nullptr, &m_ImageAvailableSemaphores[i]) != VK_SUCCESS ||
				vkCreateSemaphore(m_UniqueCpu->GetDevice(), &semaphoreInfo, nullptr, &m_RenderFinishedSemaphores[i]) != VK_SUCCESS ||
				vkCreateFence(m_UniqueCpu->GetDevice(), &fenceInfo, nullptr, &m_InFlightFences[i]) != VK_SUCCESS)
				throw std::runtime_error("failed to create synchronization objects for a frame!");

		}
	}

	void CleanupSwapChain()
	{
		for (size_t i = 0; i < m_UniqueSwapChain->GetFrameBuffers().size(); ++i)
			vkDestroyFramebuffer(m_UniqueCpu->GetDevice(), m_UniqueSwapChain->GetFrameBuffers()[i], nullptr);

		//Instead of destroying the command pool, we just clean up the exisiting command buffers
		//with vkFreeCommandBuffers. This way we can reuse the existing pool to allocate the new command buffers.
		vkFreeCommandBuffers(m_UniqueCpu->GetDevice(), m_UniqueCommandPool->GetPool(), static_cast<uint32_t>(m_CommandBuffers.size()), m_CommandBuffers.data());
		vkDestroyPipeline(m_UniqueCpu->GetDevice(), m_UniquePipeline->GetPipeline(), nullptr);
		vkDestroyPipelineLayout(m_UniqueCpu->GetDevice(), m_UniquePipeline->GetLayout()->GetPipelineLayout(), nullptr);
		//vkDestroyRenderPass(m_UniqueCpu->GetDevice(), m_UniqueRenderPass->GetRenderPass() , nullptr);

		for (size_t i = 0; i < m_UniqueSwapChain->GetImageViews().size(); ++i)
			vkDestroyImageView(m_UniqueCpu->GetDevice(), m_UniqueSwapChain->GetImageViews()[i], nullptr);

		vkDestroySwapchainKHR(m_UniqueCpu->GetDevice(), m_UniqueSwapChain->GetSwapChain(), nullptr);
	}

	void RecreateSwapChain()
	{
		int width = 0;
		int height = 0;

		while (width == 0 || height == 0)
		{
			glfwGetFramebufferSize(m_UniqueWindow->GetGLFWWindow(), &width, &height);
			glfwWaitEvents();
		}

		//To make sure we don't touch any resources that are still in use,
		//We call vkDeviceWaitIdle first.
		vkDeviceWaitIdle(m_UniqueCpu->GetDevice());

		//Clean up previous objects before recreating them
		CleanupSwapChain();

		//Recreate the swapchain itself
		//CreateSwapChain();

		//the image views need to be recreated because they are based directly on the swap chain images
		//CreateImageViews();

		//The render pass needs to be recreated because it depends on the format of the swap chain images.
		//it is rare for the swap chain image format to change during an operation like a window resize
		//but it should still be handled
		//CreateRenderPass();

		//Viewport and scissor rectangles size is speciifed during graphics pipeline creation, so the pipeline
		//also needs to be rebuilt. it is possible to avoid this by using dynamic state for the viewports and scissor rectangles.
		//CreateGraphicsPipeline();

		CreateColorResources();

		//The resolution of the depth buffer should change when the window is resized to match the new color attachment resolution.
		CreateDepthResources();

		//The frame buffers and command buffers also directly depend on the swap chain images.
		//CreateFrameBuffers();
		CreateCommandBuffers();
	}

	//The reason that we're creating a static function as a callback is because GLFW does not know how
	//to properly call a member function with the right this pointer to our HelloTriangleApplication instance.
	//However, we do get a reference to the GLFWwindow in the callback and there is another GLFW function that
	//allows you to store an arbitrary pointer inside of it: glfwSetWindowUserPointer
	static void FrameBufferResizeCallback(GLFWwindow* pWindow, int width, int height)
	{
		HelloTriangleApplication* pApp = reinterpret_cast<HelloTriangleApplication*>(glfwGetWindowUserPointer(pWindow));
		pApp->m_FrameBufferResized = true;
	}

	void CreateVertexBuffer()
	{
		VkDeviceSize bufferSize = sizeof(m_Vertices[0]) * m_Vertices.size();
		//CreateBuffer(bufferSize, VK_BUFFER_USAGE_VERTEX_BUFFER_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, m_VertexBuffer, m_VertexBufferMemory);

		VkBuffer staginBuffer;
		VkDeviceMemory stagingBufferMemory;

		//We're now using a new staginBuffer with staginBufferMemory for mapping and copying the vertex data.
		//In this chapter we're going to use 2 new buffer flags:
		//VK_BUFFER_USAGE_TRANSFER_SRC_BIT: Buffer can be used as source in a memory transfer operation.
		//VK_BUFFER_USAGE_TRANSFER_DST_BIT: Buffer can be used as destination in a memory transfer operation.

		//The m_VertexBuffer is now allocated from a memory type that is device local, which generally means
		//that we're not able to use vkMapMemory. However, we can copy data from the stagingBuffer to the m_VertexBuffer.
		//We have to indicate that we inted to do that by specifying the transfer source flag for the stagingBuffer and
		//the transfer destination flag for the m_VertexBuffer, along with the vrtex buffer usage flag.
		CreateBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, staginBuffer, stagingBufferMemory, m_UniqueCpu.get(), m_UniqueGpu.get());

		void* data;
		vkMapMemory(m_UniqueCpu->GetDevice(), stagingBufferMemory, 0, bufferSize, 0, &data);
		memcpy(data, m_Vertices.data(), (size_t)bufferSize);
		vkUnmapMemory(m_UniqueCpu->GetDevice(), stagingBufferMemory);

		CreateBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_VERTEX_BUFFER_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, m_VertexBuffer, m_VertexBufferMemory, m_UniqueCpu.get(), m_UniqueGpu.get());
		CopyBuffer(staginBuffer, m_VertexBuffer, bufferSize, m_UniqueCommandPool->GetPool(), m_UniqueCpu.get());

		vkDestroyBuffer(m_UniqueCpu->GetDevice(), staginBuffer, nullptr);
		vkFreeMemory(m_UniqueCpu->GetDevice(), stagingBufferMemory, nullptr);

		//It should be noted that in real world applications, you're not supposed to actually call vkAllocateMemory
		//for every individual buffer. The Maximum number of simultaneous memory allocations is limited by the maxMemoryAllocationCount
		//physical device limit, which may be as low as 4096 even on high end hardware like an NVIDIA GTX 1080.
		//The right way to allocate memory for a large number of objects at the same time is to create a custom allocator
		//that splits up a single allocatoin among many different objects by using the offset parameters that we've
		//seen in many functions.

		//You can either implement such an allocator yourself, or use the VulkanMemoryAllocator library provided by the GPUOpen initiave.
		//However, for this tutorial it's okay to use a seperate allocation for every resource, because we won't come close
		//to hitting any of these limits for now.

		//Copy vertices into buffer
		//Unfortunately the driver may not immediately copy the data into the buffer memory.,
		//for example because of caching. It is also possible that writings to the buffer are not viisble
		//in the mapped memory yet. There are 2 ways to deal with that problem:
		//1) Use a memory heap that is host coherent, indicated with VK_MEMORY_PROPERTY_HOST_COHERENT_BIT.
		//2) Call vkFlushMappedMemoryRanges after writing to the mapped memory, and call vkInvalidateMappedMemoryRanges
		//before reading from the mapped memory.

		//We went for the first approach, which ensures that the mapped memory always matches the contents of the allocated memory.
		//Do keep in mind that this may lead to slightly worse performance than explicit flushing.
		//but we'll see why that doesn't matter in the next chapter (Vulkan Tutorial page 168)
		//void* data;
		//vkMapMemory(m_UniqueCpu->GetDevice(), m_VertexBufferMemory, 0, bufferSize, 0, &data);
		//memcpy(data, vertices.data(), (size_t)bufferSize);
		//vkUnmapMemory(m_UniqueCpu->GetDevice(), m_VertexBufferMemory);
	}

	void CreateIndexBuffer()
	{
		//There are only 2 notable idfferences. The bufferSize is now equal to the number of indices times the size of the index type,
		//either uint16_t or uint32_t. The usage of the m_IndexBuffer should be VK_BUFFER_USAGE_INDEX_BUFFER_BIT instead
		//of VK_BUFFER_USAGE_VERTEX_BUFFER_BIT, which makes sense. Other than that, the process is exactly the same.
		//We create a staging buffer to copy the contents of m_Indices to and then copy it to the final device local index buffer.
		VkDeviceSize bufferSize = sizeof(m_Indices[0]) * m_Indices.size();

		VkBuffer stagingBuffer;
		VkDeviceMemory stagingBufferMemory;
		CreateBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, stagingBuffer, stagingBufferMemory, m_UniqueCpu.get(), m_UniqueGpu.get());

		void* data;
		vkMapMemory(m_UniqueCpu->GetDevice(), stagingBufferMemory, 0, bufferSize, 0, &data);
		memcpy(data, m_Indices.data(), (size_t)bufferSize);
		vkUnmapMemory(m_UniqueCpu->GetDevice(), stagingBufferMemory);

		CreateBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_INDEX_BUFFER_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, m_IndexBuffer, m_IndexBufferMemory, m_UniqueCpu.get(), m_UniqueGpu.get());

		CopyBuffer(stagingBuffer, m_IndexBuffer, bufferSize, m_UniqueCommandPool->GetPool(), m_UniqueCpu.get());

		vkDestroyBuffer(m_UniqueCpu->GetDevice(), stagingBuffer, nullptr);
		vkFreeMemory(m_UniqueCpu->GetDevice(), stagingBufferMemory, nullptr);
	}

	void CreateDescriptorPool()
	{
		//We first need to describe which descriptor types our descriptor sets are going to contain and
		//how many of them, using VkDescriptorPoolSize structures
		std::array<VkDescriptorPoolSize, 2> poolSizes = {};
		poolSizes[0].type = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
		poolSizes[0].descriptorCount = static_cast<uint32_t>(m_UniqueSwapChain->GetImages().size());

		poolSizes[1].type = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
		poolSizes[1].descriptorCount = static_cast<uint32_t>(m_UniqueSwapChain->GetImages().size());

		//We will allocate one of these descriptors for every frame. This pool size structure is referenced
		//ny the main VkDescriptorPoolCreateInfo:
		VkDescriptorPoolCreateInfo poolInfo = {};
		poolInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO;
		poolInfo.poolSizeCount = static_cast<uint32_t>(poolSizes.size());
		poolInfo.pPoolSizes = poolSizes.data();

		//Aside from the maimum number of individual descriptors that are available,
		//We also need to specify the maimum number of descriptors sets that may be allocated.
		poolInfo.maxSets = static_cast<uint32_t>(m_UniqueSwapChain->GetImages().size());

		//The structure has an optional flag similar to command pools that determines if individual
		//descriptor sets can be freed or not: VK_DESCRIPTOR_POOL_CREATE_FREE_DESCRIPTOR_SET_BIT.
		//We're not going to touch the descriptor set after creating it, so we don't need this flag.

		if (vkCreateDescriptorPool(m_UniqueCpu->GetDevice(), &poolInfo, nullptr, &m_DescriptorPool) != VK_SUCCESS)
			throw std::runtime_error("failed to create descriptor pool!");

	}

	void CreateDescriptorSets()
	{
		//A descriptor set allocatoin is described with a VkDescriptorSetAllocateInfo struct.
		//You need to specify the desriptor pool to allocate from, the number of descriptors sets to allocate
		//and the descriptor layour to base them on.

		std::vector<VkDescriptorSetLayout> layouts(m_UniqueSwapChain->GetImages().size(), m_UniqueDescriptorSetLayout->GetDescriptorSetLayout());

		//In our case, we will create one descriptor set for each swap chain image, all with the same layout.
		//Unfortunately we do need all the copies of the layour because the next function expects an array matching the numbers of sets.
		VkDescriptorSetAllocateInfo allocInfo = {};
		allocInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO;
		allocInfo.descriptorPool = m_DescriptorPool;
		allocInfo.descriptorSetCount = static_cast<uint32_t>(m_UniqueSwapChain->GetImages().size());
		allocInfo.pSetLayouts = layouts.data();

		m_DescriptorSets.resize(m_UniqueSwapChain->GetImages().size());

		//You don't need to explicitly clean up descriptor sets, because they will be automatically freed
		//when the desriptor pool is destroyed. The call to vkAllocateDescriptorSets will allocate descriptor
		//sets, each with one uniform buffer descriptor.
		if (vkAllocateDescriptorSets(m_UniqueCpu->GetDevice(), &allocInfo, &m_DescriptorSets[0]) != VK_SUCCESS)
			throw std::runtime_error("failed to allocate descriptor sets!");


		//The descriptor sets have been allocated now, but the descriptors within still need to be configured.
		for (size_t i = 0; i < m_UniqueSwapChain->GetImages().size(); ++i)
		{
			//Descriptors that refer to buffers, like our uniform buffer descriptor, are configured with a vkDescriptorBufferInfo.
			//This structure specifies the buffer and the region within it that contains the data for the descriptor.
			VkDescriptorBufferInfo  bufferInfo = {};
			bufferInfo.buffer = m_UniqueSwapChain->GetUniformBuffers()[i];
			bufferInfo.offset = 0;
			//If you're overwriting the whole buffer, like we are in this case, then it is also possible to use the VK_WHOLE_SIZE
			//value for the range. The configuration of descriptors is updated using the vkUpdateDescriptorsSets function,
			//which takes an array of VkWriteDescriptorSet structs as parameter.
			bufferInfo.range = sizeof(UniformBufferObject);

			//Bind the actual image and sampler resources to the descriptors in the descriptor set.

			//The resources for a combinded image sampler structure must be specified in a VkDescriptorImageInfo struct,
			//just like the buffer resource for a uniform buffer descriptor is specified in a VkDescriptorBufferInfo struct.
			VkDescriptorImageInfo imageInfo = {};
			imageInfo.imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
			imageInfo.imageView = m_UniqueTexture->GetImageView();
			imageInfo.sampler = m_TextureSampler;

			//The first 2 fields specify the descriptor set to update and the binding.
			//We gave our uniform buffer binding index 0. Remember that descriptors can be arrays, 
			//so we also need to specify the first index in the array that we want to update.
			//We're not using an array, so the index is simply 0.
			std::array<VkWriteDescriptorSet, 2> descriptorWrites = {};
			descriptorWrites[0].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
			descriptorWrites[0].dstSet = m_DescriptorSets[i];
			descriptorWrites[0].dstBinding = 0;
			descriptorWrites[0].dstArrayElement = 0;

			//We need to specify the type of descriptor again. It's possible to update multiple descriptors
			//at once in an array, starrting at index dstArrayElement. The descriptorCount field specifies
			//how many array elements you want to update.
			descriptorWrites[0].descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;

			//pBufferInfo references an array with descriptorCount structs that actually configure the descriptors.
			//It depends on the type of descriptor which one of the three you actually need to use.
			//The pBufferInfo field is usedfor descriptors that refer to buffer data, pImageInfo is used for descriptors
			//that refer to image data, and pTextBufferView is used for descriptors that refer to buffer views.
			//Our descriptor is based on buffers, so we're using pBufferInfo.
			descriptorWrites[0].descriptorCount = 1;
			descriptorWrites[0].pBufferInfo = &bufferInfo;
			descriptorWrites[0].pImageInfo = nullptr; //Optional
			descriptorWrites[0].pTexelBufferView = nullptr; //Optional

			descriptorWrites[1].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
			descriptorWrites[1].dstSet = m_DescriptorSets[i];
			descriptorWrites[1].dstBinding = 1;
			descriptorWrites[1].dstArrayElement = 0;
			descriptorWrites[1].descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
			descriptorWrites[1].descriptorCount = 1;

			//The descriptors must be updated with this image info, just like the buffer
			//This time we're using the pImageInfo array instead of pBufferinfo.
			//The descriptors are now ready to bused by the shaders!
			descriptorWrites[1].pImageInfo = &imageInfo;

			//The updates are applied using vkUpdateDescriptorSets.
			//It accepts two kinds of arrays as parameters:
			//An array of VkWriteDescriptorSet
			//An array of VkCopyDescriptorSet.
			//The latter can be used to copy descriptors to each other, as its name implies.
			vkUpdateDescriptorSets(m_UniqueCpu->GetDevice(), static_cast<uint32_t>(descriptorWrites.size()), descriptorWrites.data(), 0, nullptr);
		}

		//As some of the structues and function calls hinted at,
		//it is actually possible to bind multiple descriptor sets simultaneously.
		//You need to specify a descriptor layour for each descriptor set when creating
		//the pipeline layout. Shaders can then reference specific desciptor sets like this:
		//layout(set = 0, binding = 0) uniform UniformBufferObject { ... }

		//You can use this feature to put descriptors that vary per-object and descriptors that are
		//shared into separate descriptor sets. In that case you avoid rebinding most of the descriptors 
		//across draw call which is potentially more efficient.

	}

	void CreateTextureImage()
	{
		int texWidth, texHeight, texChannels;

		//the stbi_load function takes the file path and number of channels as arguments.
		//the STBI_rgb_alpha value forces the image to be loaded with an alpha channel, even if it doesn't have one,
		//which is nice for consistency with other textures in the future.
		//The middle 3 parameters are outputs for the dith, height and actual number of channels in the image.
		//The pointer that is returned is the first elemtn in an array of pixel values.
		//The pixels are laid out row by row with 4 bytes per pixel in the case of STBI_rgba_alpha for a total of texWidth * texHeight * 4 values.
		stbi_uc* pixels = stbi_load(TEXTURE_PATH.c_str(), &texWidth, &texHeight, &texChannels, STBI_rgb_alpha);
		VkDeviceSize imageSize = texWidth * texHeight * 4; //4 -> rgba

		//In Vulkan each of the mip images is stored in different mip levels of a VkImage.
		//Mip level 0 is the original image, and the mip levels after level 0 are commonly referred to as the mip chain.
		//The number of mip levels is specified when the VKImage is created.

		//This calculates the number of levels in the mip chain.
		//The max functions selects the largest dimension. 
		//The log2 function calculates how many times that dimension can be divided by 2.
		//The floor functoin handles case where the largest dimension is not a power of 2.
		//1 is added so that the original image has a mip level.
		m_MipLevels = static_cast<uint32_t>(std::floor(std::log2(std::max(texWidth, texHeight)))) + 1;

		if (!pixels)
			throw std::runtime_error("failed to load texture image!");

		VkBuffer stagingBuffer;
		VkDeviceMemory stagingBufferMemory;

		//The buffer should be in host visible memory so that we can map it
		//and it should be usable as a transfer source so that we can copy it to an image later on.
		CreateBuffer(imageSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, stagingBuffer, stagingBufferMemory, m_UniqueCpu.get(), m_UniqueGpu.get());

		void* data;
		vkMapMemory(m_UniqueCpu->GetDevice(), stagingBufferMemory, 0, imageSize, 0, &data);
		memcpy(data, pixels, static_cast<size_t>(imageSize));
		vkUnmapMemory(m_UniqueCpu->GetDevice(), stagingBufferMemory);

		//clean up the original pixel array
		stbi_image_free(pixels);

		//We must inform Vulkan that we intend to use the texture image as both the source and destination of a transfer.
		CreateImage(texWidth, texHeight, m_MipLevels, VK_SAMPLE_COUNT_1_BIT, VK_FORMAT_R8G8B8A8_UNORM, VK_IMAGE_TILING_OPTIMAL, VK_IMAGE_USAGE_TRANSFER_SRC_BIT | VK_IMAGE_USAGE_TRANSFER_DST_BIT | VK_IMAGE_USAGE_SAMPLED_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, m_TextureImage, m_TextureImageMemory, m_UniqueCpu.get(), m_UniqueGpu.get());

		//Copy the staging buffer to the texture image with 2 steps:
		//Transition the texture image to VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL
		//Execute the buffer to image copy operation

		//The image was created with the VK_IMAGE_LAYOUT_UNDEFFINED layout, so that one should be specified as old layout 
		//when transitioning textureImage.
		TransitionImageLayout(m_TextureImage, VK_FORMAT_R8G8B8A8_UNORM, VK_IMAGE_LAYOUT_UNDEFINED, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, m_MipLevels, m_UniqueCommandPool.get(), m_UniqueCpu.get());
		CopyBufferToImage(stagingBuffer, m_TextureImage, static_cast<uint32_t>(texWidth), static_cast<uint32_t>(texHeight), m_UniqueCommandPool->GetPool(), m_UniqueCpu.get());

		GenerateMipMaps(m_TextureImage, VK_FORMAT_R8G8B8A8_UNORM, texWidth, texHeight, m_MipLevels);
		//To be able to start sampling from the texture image in the shader, we need one last transition
		//to prepare it for shader access.
		//TransitionImageLayout(m_TextureImage, VK_FORMAT_R8G8B8A8_UNORM, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL, m_MipLevels);
		vkDestroyBuffer(m_UniqueCpu->GetDevice(), stagingBuffer, nullptr);
		vkFreeMemory(m_UniqueCpu->GetDevice(), stagingBufferMemory, nullptr);

	}

	void CreateTextureImageView()
	{
		//The code for this function can be based directly on CreateImageViews.
		//The only 2 changes you have to make are the format and the image
		m_TextureImageView = CreateImageView(m_TextureImage, VK_FORMAT_R8G8B8A8_UNORM, VK_IMAGE_ASPECT_COLOR_BIT, m_MipLevels, m_UniqueCpu.get());
	}

	void CreateTextureSampler()
	{
		VkSamplerCreateInfo samplerInfo = {};
		samplerInfo.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO;

		//The magFilter and minFilter fields specify how to interpolate texels that are magnified or minified.
		//Magnification concerns the oversampling problem, minification concerns undersampling.
		//The choices are VK_FILTER_NEAREST and VK_FILTER_LINEAR.
		samplerInfo.magFilter = VK_FILTER_LINEAR;
		samplerInfo.minFilter = VK_FILTER_LINEAR;

		//The addressing mode can be specified per axis using the addressMode fields.
		//The available values are: 
		//VK_SAMPLER_ADDRESS_MODE_REPEAT: Repeat the texture when going beyond the image dimensions.
		//VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT: Like repear, but inverts the coordinates to mirror the image when going beyond the dimensions.
		//VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE: Take the color of the edge closest to the coordinate beyond the image dimensions.
		//VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE: Like clamp to edge, but instead uses the edge opposite to the closest edge.
		//VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER: Returns a solid color when sampling beyond the dimensions of the image.
		samplerInfo.addressModeU = VK_SAMPLER_ADDRESS_MODE_REPEAT;
		samplerInfo.addressModeV = VK_SAMPLER_ADDRESS_MODE_REPEAT;
		samplerInfo.addressModeW = VK_SAMPLER_ADDRESS_MODE_REPEAT;

		//These 2 fields specify if anisotropic filtering should be used.
		//There is no reason not use this unless performance is a concern.
		//The maxAnisotropy field limits the amount of texel samples that can be used to calculate the final color.
		//A lower value results in better performance, but lower quality results.
		//There is no graphics hardware available today that will use more than 16 samples, because the difference 
		//is negligible beyond that point.
		samplerInfo.anisotropyEnable = VK_TRUE;
		samplerInfo.maxAnisotropy = 16;

		//Disable antisotropic filtering
		//samplerInfo.anisotropyEnable = VK_FALSE;
		//samplerInfo.maxAnisotropy = 1;

		//The borderColor specifies which color is returned when sampling beyond the image with clamp to border addressing mode.
		//it is possible to return black, white, transparent in either float or int formats. You cannot specify an arbitrary color.
		samplerInfo.borderColor = VK_BORDER_COLOR_INT_OPAQUE_BLACK;

		//The unnormalizedCoordinates filed specifies which coordinate system you want to use to address texels in an image.
		//If this field is VK_TRUE, then you can simply use coordinates within the [0, texWidth] and [0, texHeight] range.
		//if is is VK_FALSE, then the texesl are addressed using the [0,1] range on all axes.
		//Real-World applications almost always use normalized coordinates, because then it's possible to use textures of varying
		//resolutions with the exact same coordinates.
		samplerInfo.unnormalizedCoordinates = VK_FALSE;

		//if a comparison function is enabled, then texels will first be compared to a value and
		//the result of that comparison is used in filtering operations. This is mainly used for percentage-closer
		//filtering on shadow maps.
		samplerInfo.compareEnable = VK_FALSE;
		samplerInfo.compareOp = VK_COMPARE_OP_ALWAYS;

		//All of these fields apply to mipmapping. We will look at mipmapping in a later chapter, 
		//but basically it's another type of filter that can be applied.
		samplerInfo.mipmapMode = VK_SAMPLER_MIPMAP_MODE_LINEAR;
		samplerInfo.mipLodBias = 0.0f;
		samplerInfo.minLod = 0.0f;
		samplerInfo.maxLod = static_cast<float>(m_MipLevels);

		//Note that the sampler does not reference a VkImage anywhere. The sampler is a distinct object
		//that provides an interface to extract colors from a texture.
		//It can be applied to any image you want, whether it is 1D, 2D or 3D. This is different from
		//many older APIs, which combinded texture images and filtering into a single state.
		if (vkCreateSampler(m_UniqueCpu->GetDevice(), &samplerInfo, nullptr, &m_TextureSampler) != VK_SUCCESS)
			throw std::runtime_error("failed to create texture sampler!");

	}

	void CreateDepthResources()
	{
		//Creating a depth image is fairly straightforward. It should have the same resolution as the color
		//attachment, defined by the swap chain extent, an image usage appropriate for a depth attachment, 
		//optimal tiling and device local memory.

		//Unlike the texture image, we do'nt necessarily need a specific format, because we won't be directly accessing
		//the texels from the program. It just needs to have a reasonable accuracy, at least 23 bits is common in real-wrold applications.
		//There are several formats that fit this requirement:
		//VK_FORMAT_D32_SFLOAT: 32-bit float for depth
		//VK_FORMAT_D32_SFLOAT_S8_UINT: 32-bit signed float for depth and 8 bit stencil component
		//VK_FORMAT_D24_UNORM_S8_UINT: 24-bit float for depth and 8 bit stencil component
		//The stencil component is used for stencil tests, which is an additional test that can be combined with depth testing.
		m_UniqueDepthBuffer = std::make_unique<Buffer2D>(m_UniqueCpu.get(), m_UniqueCommandPool.get(), m_UniqueRenderPass.get(), m_UniqueSwapChain.get(), m_UniqueGpu.get(), VK_IMAGE_TILING_OPTIMAL, VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, FindDepthFormat(m_UniqueGpu.get()));

		//VkFormat depthFormat = FindDepthFormat(m_UniqueGpu.get());
		//CreateImage(m_UniqueSwapChain->GetExtent().width, m_UniqueSwapChain->GetExtent().height, 1, m_UniqueRenderPass->GetSamplesCount(), depthFormat, VK_IMAGE_TILING_OPTIMAL, VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, m_DepthImage, m_DepthImageMemory, m_UniqueCpu.get(), m_UniqueGpu.get());
		//m_DepthImageView = CreateImageView(m_DepthImage, depthFormat, VK_IMAGE_ASPECT_DEPTH_BIT, 1, m_UniqueCpu.get());

		////The undefined layout can be used as initial layout, becasue there are no existing depth image contets that matter.
		////We need to update some of the logic in transitionImageLayout to use the right subrouse aspect.
		//TransitionImageLayout(m_DepthImage, depthFormat, VK_IMAGE_LAYOUT_UNDEFINED, VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL, 1, m_UniqueCommandPool.get(), m_UniqueCpu.get());

	}

	void LoadModel()
	{
		tinyobj::attrib_t attrib;
		std::vector<tinyobj::shape_t> shapes;
		std::vector<tinyobj::material_t> materials;
		std::string warning;
		std::string err;

		//The attrib containter holds all of the positions, normals and texture coordinates in its attrib.vertices,
		//attrib.normals and attrib.texcoords vectors.
		//The shapes container contains all of the separate objects and their faces. each face consists of an array
		//of vertices, and each vertex contains the indices of the position, normal and texture coordinate attributes.
		//The warning and err string contain warning and errors that occurred while loading the file, lie a missing material
		//definition. Loading only really failed if the LoadObj function returns false.
		//As mentioned above, faces in OBJ files can actually contain an arbitrary number of vertices, whereas our application
		//can only render triangles. Luckily the LoadObj has an optional parameter to automatically triangulate such faces,
		//which is enabled by default.
		if (!tinyobj::LoadObj(&attrib, &shapes, &materials, &warning, &err, MODEL_PATH.c_str()))
			throw std::runtime_error(err);

		std::unordered_map<Vertex, uint32_t> uniqueVertices = {};

		for (const tinyobj::shape_t& shape : shapes)
		{
			for (const tinyobj::index_t& index : shape.mesh.indices)
			{
				Vertex vertex = {};

				//For simplicity, we will assume that every vertex is unqie for now, hence the simple auto-increment indices.
				//The index variable is of type tinyobj::index_t, which contains the vertex_index, normal_index and texcoord_index members.
				//We need to use these indices to look up the actual vertex attributes in the attrib arrays

				//Unfortunately the attrib.vertices array is an array of float values instead of something like glm::vec3,
				//so you need to multiply the index by 3.
				//Similarly there are 2 texture coordinate components per entry. 
				//The offsets of 0,1 and 2 are used to access the x, y and z components, or the u and v components in the case of texture coordinates
				vertex.Position =
				{
					attrib.vertices[3 * index.vertex_index + 0],
					attrib.vertices[3 * index.vertex_index + 1],
					attrib.vertices[3 * index.vertex_index + 2]
				};

				vertex.TexCoord =
				{
					attrib.texcoords[2 * index.texcoord_index + 0],

					//OpenGL expects the top to be 0 while vulkan expect it to be the bottom
					1.0f - attrib.texcoords[2 * index.texcoord_index + 1]
				};

				vertex.Color = { 1.0f, 1.0f, 1.0f };

				//Every time we read a vertex from the OBJ file, we check if we've already seen a vertex
				//with the exact same position and textrue coordinates before. if not, we add it to vertices
				//and store its index in the uniqueVertices container. after that we add the index of the new vertex
				//to indices. if We've seen the exact same vertex before, then we look up its index in uniqueVertices and store
				//that index in m_Indices.
				if (uniqueVertices.count(vertex) == 0)
				{
					uniqueVertices[vertex] = static_cast<uint32_t>(m_Vertices.size());
					m_Vertices.push_back(vertex);
				}
				
				m_Indices.push_back(uniqueVertices[vertex]);
			}
		}

		std::cout << "[loaded model]" << std::endl;
	}

	void GenerateMipMaps(VkImage image, VkFormat format, int32_t texWidth, int32_t texHeight, uint32_t mipLevels)
	{
		//Check if image formt supports linear blitting
		//The VkFormatProperties has 3 fields named linearTilingFeatures, optimalTilingFeatures and bufferFeatues.
		//that each describe how the format can be used depending on the way it is used. we create a texture image
		//with the optimal tiling format, so we need to check optimalTilingFeatures. //Support for the linear filtering feature
		//can bechecked with the VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT.
		VkFormatProperties formatProps;
		vkGetPhysicalDeviceFormatProperties(m_UniqueGpu->GetDevice(), format, &formatProps);

		//There are 2 alternatives in this case. You could implement a function that searches common texture image
		//formats for one that does support linear blitting, or you could implement the mipmap generation in software
		//with a library like stb_image_resize. Each mip level can then be loaded into the image in the same way 
		//that you loaded the orignal image.

		//It should be noted that it is uncommon in practice to generate the mipmap levels at runtime anywah.
		//Usually they are pregenerated and stored in the texture file alongside the base level to improve loading speed.
		//Implmenting resizing in software and loading multiple levels from a file is left as an exercise to the reader.
		if (!(formatProps.optimalTilingFeatures & VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT))
			throw std::runtime_error("texture image format does not support linear blitting!");

		VkCommandBuffer commandBuffer = BeginSingleTimeCommands(m_UniqueCommandPool->GetPool(), m_UniqueCpu.get());

		VkImageMemoryBarrier barrier = {};
		barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
		barrier.image = image;
		barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
		barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
		barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
		barrier.subresourceRange.baseArrayLayer = 0;
		barrier.subresourceRange.layerCount = 1;
		barrier.subresourceRange.levelCount = 1;

		int32_t mipWidth = texWidth;
		int32_t mipHeight = texHeight;
		
		for (uint32_t i = 1; i < mipLevels; ++i)
		{
			//First, we transition level i - 1 to VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL.
			//THis transition will wait for level i - 1 to be filled, either from the previous blit command
			//or from vkCmdCopyBufferToImage. The current blit command will wait on this transition
			barrier.subresourceRange.baseMipLevel = i - 1;
			barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
			barrier.newLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
			barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
			barrier.dstAccessMask = VK_ACCESS_TRANSFER_READ_BIT;

			vkCmdPipelineBarrier(commandBuffer, VK_PIPELINE_STAGE_TRANSFER_BIT, VK_PIPELINE_STAGE_TRANSFER_BIT, 0, 0, nullptr, 0, nullptr, 1, &barrier);

			//Next, we specify the regoins that will be used in the blit operation.
			//The source mip level is i - 1 and the destination mip level is i.
			//The 2 elements of the srcOffsets array determine the 3D region that data will be blitted from
			//dstOffsets determines the region that data will be blitted to.
			//The x and y dimensions of the dstOffsets[1] are divided by 2 since each mip level is half the size of the previous level.
			//The z dimension of srcOffsets[1] and dstOffsets[1] must be 1, since a 2D image has a depth of 1.
			VkImageBlit blit = {};
			blit.srcOffsets[0] = { 0,0,0 };
			blit.srcOffsets[1] = { mipWidth, mipHeight, 1 };
			blit.srcSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
			blit.srcSubresource.mipLevel = i - 1;
			blit.srcSubresource.baseArrayLayer = 0;
			blit.srcSubresource.layerCount = 1;
			blit.dstOffsets[0] = { 0,0,0 };
			blit.dstOffsets[1] = { mipWidth > 1 ? static_cast<int32_t>(mipWidth * 0.5f) : 1, mipHeight > 1 ? static_cast<int32_t>(mipHeight * 0.5f) : 1, 1 };
			blit.dstSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
			blit.dstSubresource.mipLevel = i;
			blit.dstSubresource.baseArrayLayer = 0;
			blit.dstSubresource.layerCount = 1;

			//Now we record the blit command. Note that m_TextureImage is used for both srcImage and dstImage parameter.
			//This is because we're blitting between different levels of the same image.
			//The source mip level was just transitioned to VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL and
			//the destination level is still in VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL from CreateTextureImage.
			//The last parameter allows us to specify a VkFilter to use in the blit. we have the same filtering options
			//here that we had when making the VkSampler. We use the VK_FILTER_LINEAR to enable interpolation.
			vkCmdBlitImage(commandBuffer, 
				image, VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
				image, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 
				1, &blit, VK_FILTER_LINEAR);

			barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
			barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
			barrier.srcAccessMask = VK_ACCESS_TRANSFER_READ_BIT;
			barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;

			//This barrier transitions mip level i - 1 to VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL.
			//This transition waits on the current blit command to finish. All sampling operations will wait on this transiton to finish.
			vkCmdPipelineBarrier(commandBuffer, VK_PIPELINE_STAGE_TRANSFER_BIT, VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT, 0, 0, nullptr, 0, nullptr, 1, &barrier);

			if (mipWidth > 1) mipWidth /= 2;
			if (mipHeight > 1) mipHeight /= 2;
		}

		//before we end the command buffer, we insert one more pipeline barrier. This barrier transitions the last
		//mip level from VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL to VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL. 
		//This wasn't handled by the loop, since the last mip level is never blitted from
		barrier.subresourceRange.baseMipLevel = m_MipLevels - 1;
		barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
		barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
		barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
		barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;

		vkCmdPipelineBarrier(commandBuffer, VK_PIPELINE_STAGE_TRANSFER_BIT, VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT, 0, 0, nullptr, 0, nullptr, 1, &barrier);

		EndSingleTimeCommands(commandBuffer, m_UniqueCommandPool->GetPool(), m_UniqueCpu.get());
	}

	void CreateColorResources()
	{
		m_UniqueRenderTarget = std::make_unique<Buffer2D>(m_UniqueCpu.get(), m_UniqueCommandPool.get(),m_UniqueRenderPass.get(), m_UniqueGpu.get(),
			m_UniqueSwapChain->GetExtent().width, m_UniqueSwapChain->GetExtent().height, 
			VK_IMAGE_TILING_OPTIMAL, VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT | VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, 
			m_UniqueSwapChain->GetFormat(), VK_IMAGE_ASPECT_COLOR_BIT, VK_IMAGE_LAYOUT_UNDEFINED, VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL);

		/*VkFormat colorFormat = m_UniqueSwapChain->GetFormat();

		CreateImage(m_UniqueSwapChain->GetExtent().width, m_UniqueSwapChain->GetExtent().height, 1,
			m_UniqueRenderPass->GetSamplesCount(), colorFormat,
			VK_IMAGE_TILING_OPTIMAL, VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT | VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT, 
			VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, 
			m_ColorImage, m_ColorImageMemory,
			m_UniqueCpu.get(), m_UniqueGpu.get());

		m_ColorImageView = CreateImageView(m_ColorImage, colorFormat, VK_IMAGE_ASPECT_COLOR_BIT, 1, m_UniqueCpu.get());

		TransitionImageLayout(m_ColorImage, colorFormat, VK_IMAGE_LAYOUT_UNDEFINED, VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL, 1, m_UniqueCommandPool.get(), m_UniqueCpu.get());*/
	}

private:
	std::unique_ptr<Window> m_UniqueWindow;
	std::unique_ptr<VulkanInstance> m_UniqueInstance;
	std::unique_ptr<Surface> m_UniqueSurface;
	std::unique_ptr<PhysicalDevice> m_UniqueGpu;
	std::unique_ptr<LogicalDevice> m_UniqueCpu;
	std::unique_ptr<SwapChain> m_UniqueSwapChain;
	std::unique_ptr<RenderPass> m_UniqueRenderPass;
	std::unique_ptr<DescriptorSetLayout> m_UniqueDescriptorSetLayout;
	std::unique_ptr<GraphicsPipeline> m_UniquePipeline;
	std::unique_ptr<CommandPool> m_UniqueCommandPool;

	//In MSAA, each pixel is sampled in an offscreen buffer which is then rendered to the screen.
	//This new buffer is silghtly different from regular images we've been rendering to, 
	//they have to be able to store more than one sample per pixel. Once a multisampled buffer is created,
	// it has to be resolved to the default framebuffer (which stores only a single sample per pixel). 
	//This is why we have to create an additional render target and modifgy our current drawing procsess.
	//We only need one render target since only one drawing operation is actie at a time, just like with
	//the depth buffer.
	std::unique_ptr<Buffer2D> m_UniqueRenderTarget;
	std::unique_ptr<Buffer2D> m_UniqueDepthBuffer;
	std::unique_ptr<Buffer2D> m_UniqueTexture;

	std::vector<VkCommandBuffer> m_CommandBuffers;

	//Each frame should have its own set of semaphores
	std::vector<VkSemaphore> m_ImageAvailableSemaphores;
	std::vector<VkSemaphore> m_RenderFinishedSemaphores;
	std::vector<VkFence> m_InFlightFences;
	size_t m_CurrentFrame = 0;
	bool m_FrameBufferResized = false;
	VkBuffer m_VertexBuffer;
	VkDeviceMemory m_VertexBufferMemory;

	//Just like the vertex data, the indices need to be uploaded into a VkBuffer for the GPU to be able to access them.
	VkBuffer m_IndexBuffer;
	VkDeviceMemory m_IndexBufferMemory;
	VkDescriptorPool m_DescriptorPool;
	std::vector<VkDescriptorSet> m_DescriptorSets;
	uint32_t m_MipLevels;
	//VkImage m_TextureImage;
	//VkDeviceMemory m_TextureImageMemory;
	//VkImageView m_TextureImageView;
	VkSampler m_TextureSampler;

	const std::vector<const char*> m_ValidationLayers = { "VK_LAYER_LUNARG_standard_validation" };
	const std::vector<const char*> m_DeviceExtensions = { VK_KHR_SWAPCHAIN_EXTENSION_NAME };

	const int MAX_FRAMES_IN_FLIGHT = 2;

	//Interleaving vertex attributes: all vertices and their attributes are defined in 1 buffer
	std::vector<Vertex> m_Vertices;
	//{
	//	//		Position				Color			TexCoord
	//	//-----------------------------------------------------------
	//	{{-0.5f, -0.5f,  0.0f},  {1.0f, 0.0f, 0.0f},  {1.0f, 0.0f}},
	//	{{ 0.5f, -0.5f,  0.0f},  {0.0f, 1.0f, 0.0f},  {0.0f, 0.0f}},
	//	{{ 0.5f,  0.5f,  0.0f},  {0.0f, 0.0f, 1.0f},  {0.0f, 1.0f}},
	//	{{-0.5f,  0.5f,  0.0f},  {1.0f, 1.0f, 1.0f},  {1.0f, 1.0f}},

	//	{{-0.5f, -0.5f, -0.5f},  {1.0f, 0.0f, 0.0f},  {1.0f, 0.0f}},
	//	{{ 0.5f, -0.5f, -0.5f},  {0.0f, 1.0f, 0.0f},  {0.0f, 0.0f}},
	//	{{ 0.5f,  0.5f, -0.5f},  {0.0f, 0.0f, 1.0f},  {0.0f, 1.0f}},
	//	{{-0.5f,  0.5f, -0.5f},  {1.0f, 1.0f, 1.0f},  {1.0f, 1.0f}}
	//};

	/*
	-------
	|\    |
	| \ 1 |
	|  \  |
	| 2 \ |
	|    \|
	-------
	*/

	//It is possible to use either uin16_t or uin32_t for your index buffer depending on the number
	//of entries in vertices. We can stick to uint16_t for now because we're using less than 65534 unique vertices
	std::vector<uint32_t> m_Indices;
	//{
	//	//First plane
	//	0,1,2, //top right
	//	2,3,0,  //bottom left

	//	//Second plane
	//	4,5,6, //top right
	//	6,7,4 //bottom left
	//};

	const uint32_t WIDTH = 800;
	const uint32_t HEIGHT = 600;

	const std::string MODEL_PATH = "../data/meshes/chalet.obj";
	const std::string TEXTURE_PATH = "../data/textures/chalet.jpg";

};

int Program()
{
	HelloTriangleApplication app;

	try
	{
		app.Run();
	}
	catch (const std::exception& e)
	{
		std::cerr << e.what() << std::endl;
		return EXIT_FAILURE;
	}

	return EXIT_SUCCESS;
}

int main()
{
	int errCode = Program();
	std::cin.get();
	return errCode;
}